{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Linear regression is the simplest linear method used for modelling the relationship between the independent variables and the dependent ones. It tries to estimate it by finding a line which is as close as possible to all the data points. \n",
    "\n",
    "\\begin{equation}\n",
    "y=ax+b\n",
    "\\end{equation}\n",
    "\n",
    "#### Boston housing example\n",
    "\n",
    "[Boston housing](https://www.kaggle.com/c/boston-housing) is a very simple dataset built from some statistical data of the houses of Boston suburbs and the median prices (in $1000s) of owner-occupied homes for each zone."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< 618ab3556c725e4c090e61c12f73733ec2b5b9d6
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
=======
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "testfile\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n\n   PTRATIO       B  LSTAT  MEDV  \n0     15.3  396.90   4.98  24.0  \n1     17.8  396.90   9.14  21.6  \n2     17.8  392.83   4.03  34.7  \n3     18.7  394.63   2.94  33.4  \n4     18.7  396.90   5.33  36.2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
>>>>>>> modifications during first attempt to clustering exercises, % store -r is NOT working
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "print('testfile')\n",
    "# Loading the dataset with pandas\n",
    "boston_data = load_boston()\n",
    "boston_housing_df = pd.DataFrame(boston_data.data,columns=boston_data.feature_names)\n",
    "boston_housing_df[\"MEDV\"] = boston_data.target\n",
    "boston_housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several features in the dataset:\n",
    "\n",
    "* **crim**  per capita crime rate by town.\n",
    "* **zn** proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "* **indus** proportion of non-retail business acres per town.\n",
    "* **chas** Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "* **nox** nitrogen oxides concentration (parts per 10 million).\n",
    "* **rm** average number of rooms per dwelling.\n",
    "* **age** proportion of owner-occupied units built prior to 1940.\n",
    "* **dis** weighted mean of distances to five Boston employment centres.\n",
    "* **rad** index of accessibility to radial highways.\n",
    "* **tax** full-value property-tax rate per \\$10000\n",
    "* **ptratio** pupil-teacher ratio by town.\n",
    "* **black** 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
    "* **lstat** lower status of the population (percent).\n",
    "* **medv** median value of owner-occupied homes in \\$1000s.\n",
    "\n",
    "The target variable $y$ is called *medv*.\n",
    "\n",
    "#### 2D linear regression\n",
    "\n",
    "For the simplicity, we'll consider a 2D example and try to predict the *medv* (median value), given *crim* (per capita crime rate). Let's take a look at the data in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "boston_housing_df.plot(x=\"CRIM\", y=\"MEDV\", kind=\"scatter\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create an instance of LinearRegression and find the coeffs\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X=boston_housing_df[[\"CRIM\"]], \n",
    "                      y=boston_housing_df[\"MEDV\"])\n",
    "linear_regression.coef_, linear_regression.intercept_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to draw the linear regression $y$ using matplotlib. In the code below we take the MEDV features as $y$ and CRIM as $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a polynomial to be drawn on the plot\n",
    "coefficients = np.append(linear_regression.coef_, \n",
    "                         linear_regression.intercept_)\n",
    "polynomial = np.poly1d(coefficients)\n",
    "\n",
    "# Calculate the values for a selected range\n",
    "x_values = np.linspace(0, boston_housing_df[\"CRIM\"].max())\n",
    "y_values = polynomial(x_values)\n",
    "\n",
    "# Display a scatter plot: crim vs medv and regressed line\n",
    "boston_housing_df.plot(x=\"CRIM\", y=\"MEDV\", kind=\"scatter\")\n",
    "plt.plot(x_values, y_values, color=\"red\", linestyle=\"dashed\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = linear_regression.predict(boston_housing_df[[\"CRIM\"]]) \n",
    "y_true = boston_housing_df[\"MEDV\"]\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional linear regression\n",
    "\n",
    "An intuitive selection of the possibile predictor did not help to perform a regression of the median value in the area properly. For a low crime rate it looks better, but when it comes to really high crime rate, the predicted value is negative.\n",
    "\n",
    "For the purposes of selecting predictors, we may consider the variables which have the highest correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation coefficients\n",
    "boston_housing_df.corr()[\"MEDV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute value of correlation coefficients is highest for *rm* (0.689598) and *lstat* (-0.738600). That means, these values are possibly the best predictors for the target variable and we can consider them in a 3D regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Display 3D scatter: rm, lstat vs medv\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(boston_housing_df[\"RM\"], boston_housing_df[\"LSTAT\"], \n",
    "           boston_housing_df[\"MEDV\"], c=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the coefficiencies and build a linear regression instance."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< 618ab3556c725e4c090e61c12f73733ec2b5b9d6
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
=======
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-da26cf54665f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlinear_regression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m linear_regression.fit(X=boston_housing_df[[\"RM\", \"LSTAT\"]], \n\u001b[0;32m      3\u001b[0m                       y=boston_housing_df[\"MEDV\"])\n\u001b[0;32m      4\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error"
>>>>>>> modifications during first attempt to clustering exercises, % store -r is NOT working
    }
   },
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X=boston_housing_df[[\"RM\", \"LSTAT\"]], \n",
    "                      y=boston_housing_df[\"MEDV\"])\n",
    "linear_regression.coef_, linear_regression.intercept_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a three-dimensional case we need to calculate three values. We get three coeffiencies that are used to get the $z$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate coefficients of 2d polynomial\n",
    "coefficients = np.append(linear_regression.coef_, \n",
    "                         linear_regression.intercept_)\n",
    "\n",
    "# Calculate the values for a selected range\n",
    "x = np.linspace(0, boston_housing_df[\"RM\"].max())\n",
    "y = np.linspace(0, boston_housing_df[\"LSTAT\"].max())\n",
    "x_values, y_values = np.meshgrid(x, y)\n",
    "z_values = coefficients[0] * x_values + coefficients[1] * y_values + coefficients[2]\n",
    "\n",
    "# Display 3D scatter: rm, lstat vs medv and regressed line\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(boston_housing_df[\"RM\"], boston_housing_df[\"LSTAT\"], \n",
    "           boston_housing_df[\"MEDV\"], c=\"blue\")\n",
    "ax.plot_surface(x_values, y_values, z_values, linewidth=0.2, \n",
    "                color=\"red\", alpha=0.5)\n",
    "angle=30\n",
    "ax.view_init(30, angle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction of linear regression can be done with the ``predict`` method. The cost function of a linear regression is calculated with mean squared error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = linear_regression.predict(boston_housing_df[[\"RM\", \"LSTAT\"]]) \n",
    "y_true = boston_housing_df[\"MEDV\"]\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression under the hood\n",
    "\n",
    "To understand the method in more details we use a simple example of humans heights and weights values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "heights = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1)\n",
    "weights = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we use the linear regression available in sklearn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(heights, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous example, we can plot the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(heights, weights,color='g')\n",
    "plt.plot(heights, regr.predict(heights),color='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coeffieciencies are calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(regr.coef_)\n",
    "print(regr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we calcualte the $y$ value for $x=150$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(heights, weights,color='g')\n",
    "plt.plot(heights, regr.predict(heights),color='k')\n",
    "\n",
    "x= 150\n",
    "y = 61.797\n",
    "plt.scatter(x, y,color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression from scratch\n",
    "\n",
    "And now we can use the data set to implement the linear regression from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x = heights.reshape(15,1)\n",
    "y = weights.reshape(15,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should add the bias column before doing the calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.append(x, np.ones((15,1)), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for calculating the weights is \n",
    "\\begin{equation}\n",
    "(X^{T}X)^{-1}X^{T}y\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "w = np.dot(np.linalg.inv(np.dot(np.transpose(x),x)),np.dot(np.transpose(x),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weitghs we can as the output are exaclty the same as we get using sklearn implementation of the linear regression method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the prediction a bit easier, we can implement a short function where the arguments are: \n",
    "- inputs - feature $x$ of objects,\n",
    "- w - weights,\n",
    "- b - bias.\n",
    "The calculation is easy and use the linear regression equation $y=wx+b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def reg_predict(inputs, w, b):\n",
    "    results = []\n",
    "    for inp in inputs:\n",
    "        results.append(inp*w+b)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the predicted values using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(heights.flatten(), weights.flatten(),color='g')\n",
    "plt.plot(heights.flatten(), reg_predict(heights.flatten(), w[0], w[1]) ,color='k')\n",
    "\n",
    "x1 = 150\n",
    "y = reg_predict([x1], w[0], w[1])[0]\n",
    "plt.scatter(x1, y,color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< 618ab3556c725e4c090e61c12f73733ec2b5b9d6
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
=======
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2b9f5717759f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreg_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reg_predict' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'reg_predict' is not defined",
     "output_type": "error"
>>>>>>> modifications during first attempt to clustering exercises, % store -r is NOT working
    }
   },
   "outputs": [],
   "source": [
    "reg_predict(x.flatten(), w[1], w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression\n",
    "\n",
    "Ridge regression use a regularizer and the equation is a bit more complex compare to the regular linear regression:\n",
    "\\begin{equation}\n",
    " \\sum_{i=1}^{M}(y_{i}-\\sum_{j=0}^{p}w_{j}\\dot x_{ij})^{2} + \\lambda\\sum_{j=0}^{p}w^{2}_{j}.\n",
    "\\end{equation}\n",
    "We have an additional parameter $\\lambda$ that is known in sklearn as $\\alpha$. It's the regularizer that together with $w^{2}_{j}$ is known as the L2 regularizator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "heights1 = np.asmatrix(np.c_[np.ones((15,1)), heights])\n",
    "\n",
    "ridge_regression = Ridge(alpha=alpha, fit_intercept=False)\n",
    "ridge_regression.fit(X=heights1, \n",
    "                      y=weights)\n",
    "ridge_regression.coef_, ridge_regression.intercept_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the regular linear regression, the slop can be drawn as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(heights, weights,color='g')\n",
    "plt.plot(heights, ridge_regression.predict(heights1),color='k')\n",
    "\n",
    "x = 150\n",
    "y = reg_predict([150], ridge_regression.coef_[0][1], ridge_regression.coef_[0][0])[0]\n",
    "plt.scatter(x, y,color='r')\n",
    "\n",
    "y = ridge_regression.coef_[0][1] * 150 + ridge_regression.coef_[0][0]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $x_{1}=150$ the result is a bit different compared to the regression without the regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y = ridge_regression.coef_[0][1] * 150 + ridge_regression.coef_[0][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write the equation in a matrix-way as:\n",
    "\\begin{equation}\n",
    "(X^{T}X+\\alpha\\dot W)^{-1}X^{T}y\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y = weights\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),heights])\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = 0.1\n",
    "\n",
    "w = np.linalg.inv(x.T*x + alpha * I)*x.T*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are calculated same as in case of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "w=w.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot looks as below. We see the the slope start with higer $y$ values compared to the regular linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(heights, weights, color='g')\n",
    "plt.plot(heights, reg_predict(heights.flatten(), w[1], w[0]),color='k')\n",
    "\n",
    "\n",
    "x1= 150\n",
    "y = x*w[1]+w[0] \n",
    "plt.scatter(x1, y,color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression\n",
    "\n",
    "Lasso regression uses the L1 regularization. The equation is very similar to the Ridge one, but instead of $w^{2}$ we use the magnitude of $w$. \n",
    "\n",
    "\\begin{equation}\n",
    " \\sum_{i=1}^{M}(y_{i}-\\sum_{j=0}^{p}w_{j}\\dot x_{ij})^{2} + \\lambda\\sum_{j=0}^{p}|w_{j}|.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha = 0.1\n",
    "heights1 = np.asmatrix(np.c_[np.ones((15,1)), heights])\n",
    "\n",
    "lasso_regression = Lasso(alpha=alpha)\n",
    "lasso_regression.fit(X=heights, \n",
    "                      y=weights)\n",
    "lasso_regression.coef_, lasso_regression.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(heights, weights,color='g')\n",
    "plt.plot(heights, lasso_regression.predict(heights),color='k')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-root-py",
   "language": "python",
   "display_name": "Python [conda env:root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}